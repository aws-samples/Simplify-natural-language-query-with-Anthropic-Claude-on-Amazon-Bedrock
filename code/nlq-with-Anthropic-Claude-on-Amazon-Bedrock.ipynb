{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f1b02b8-227a-4edc-b19c-484fe3358205",
   "metadata": {},
   "source": [
    "# Simplify natural language query using Anthropic Claude on Amazon Bedrock\n",
    "---\n",
    "\n",
    "In this notebook, we will explore on how to use multi-modal capabilities from **Anthropic Claude** foundation model, which is available on **Amazon Bedrock**.\n",
    "\n",
    "By feeding the entity relationship diagram (ERD) on image channel and the user's question onto text prompt channel, LLM can generate the SQL statement for querying the data lake by using **Amazon Athena** service.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dfa168-bfc6-436c-b43e-d174b091849b",
   "metadata": {},
   "source": [
    "## Set up\n",
    "---\n",
    "\n",
    "### Upgrade boto3\n",
    "\n",
    "Ensure our environment is using the most up-to-date `boto3` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48886b01-a862-481a-9f3a-8005a6c66e40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade boto3 --quiet --root-user-action=ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a682a50d-d3bb-4b6c-b537-f69987cd037e",
   "metadata": {},
   "source": [
    "### Define logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd257fd9-db09-457f-ac73-100ef56c86be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    format='[%(asctime)s] p%(process)s {%(filename)s:%(lineno)d} %(levelname)s - %(message)s', \n",
    "    level=logging.INFO\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d25e45-13b1-4b8f-adbe-b9f59582cb07",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "---\n",
    "The dataset is currently in csv file format and is available in `../data` folder, please note that this dataset is synthetic. The entity relationship diagram (ERD) is also available in `../schema_img` folder, and needs for our foundation model in the next step.\n",
    "\n",
    "<img src='../schema_img/schema.png' alt='dataset schema'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed458364-f585-45ca-8615-2d3c58922bb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_dir = '../data'\n",
    "file_list = [filename for filename in os.listdir(data_dir) if '.csv' in filename]\n",
    "logger.info(file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34334810-634a-44e4-8525-44f8ccaeb291",
   "metadata": {},
   "source": [
    "### Upload dataset to Amazon S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fce4c7-a908-4963-a935-65f6822b8bd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import botocore\n",
    "import sagemaker\n",
    "import json\n",
    "from typing import Optional, Dict, Tuple, List\n",
    "\n",
    "boto_session = boto3.session.Session()\n",
    "region_name = boto_session.region_name\n",
    "s3_client = boto3.client(service_name='s3', region_name=region_name)\n",
    "s3_bucket_name = sagemaker.Session().default_bucket()  # change this to your S3 bucket of choices\n",
    "s3_prefix_name = 'sample-datasets/raw/consulting-company'  # change this to your S3 prefix of choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199b5b6a-7c80-4a57-a96a-6ef2581e0d36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for file in file_list:\n",
    "    logger.info('Uploading {0}/{1} ...'.format(data_dir, file))\n",
    "    file_ext = file.split('.')[-1]\n",
    "    file_nm = file.split('.')[0]\n",
    "    try:\n",
    "        with open('{0}/{1}'.format(data_dir, file), 'rb') as data:\n",
    "            s3_client.upload_fileobj(\n",
    "                data,\n",
    "                s3_bucket_name, \n",
    "                '{0}/{1}/{2}'.format(s3_prefix_name, file_nm, file)\n",
    "            )\n",
    "    except Exception as e:\n",
    "        logger.error('Something is wrong! {}'.format(e))\n",
    "        raise(e)\n",
    "        \n",
    "logger.info('completed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1caacaa1-893b-4bb8-8ea2-063c7e7f5571",
   "metadata": {},
   "source": [
    "### Set up Glue Data Catalog\n",
    "---\n",
    "\n",
    "In this section, I will create Glue Data Catalog based on the uploaded CSV files:\n",
    "\n",
    "1. Glue database which will host the data from Glue Crawler\n",
    "2. Set up IAM role for Glue Crawler\n",
    "3. Create AWS Glue Crawler\n",
    "4. Start the crawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e93ce4-3318-4413-b0ad-2906ea8806db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "glue_db_name = 'demo-nlq-db'  # change this accordingly to your choices\n",
    "glue_client = boto_session.client(\n",
    "    service_name='glue',\n",
    "    region_name=region_name,\n",
    ")\n",
    "\n",
    "try:\n",
    "    logger.info('Attempting to create DB: {}'.format(glue_db_name))\n",
    "    create_db_resp = glue_client.create_database(\n",
    "        DatabaseInput={\n",
    "            'Name': glue_db_name,\n",
    "            'Description': 'Sample DB for NLQ use case'\n",
    "        }\n",
    "    )\n",
    "    logger.info('Finish creating DB')\n",
    "    \n",
    "except ClientError as e:\n",
    "    logger.error(e)\n",
    "    get_db_resp = glue_client.get_databases()\n",
    "    glue_db_name = [db['Name'] for db in get_db_resp['DatabaseList'] if db['Name'] == glue_db_name][0]\n",
    "\n",
    "logger.info('Database to use: {}'.format(glue_db_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb15ea4-cbd0-4301-81fd-6f06d71e2e53",
   "metadata": {},
   "source": [
    "### Create Glue Crawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dffc3ec-db94-44bc-bcc1-a6ec04264506",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "\n",
    "iam_client = boto_session.client(\n",
    "    service_name='iam', \n",
    "    region_name=region_name\n",
    ")\n",
    "glue_role_name = 'demo-glue-nlq'\n",
    "\n",
    "try:\n",
    "    logger.info('Attempt to create IAM role')\n",
    "    assume_role_policy_doc = {\n",
    "        'Version': '2012-10-17',\n",
    "        'Statement': [{\n",
    "            'Effect': 'Allow',\n",
    "            'Action': 'sts:AssumeRole',\n",
    "            'Principal': {\n",
    "                'Service': 'glue.amazonaws.com'\n",
    "            }\n",
    "        }]\n",
    "    }\n",
    "    assume_role_policy_doc_json = json.dumps(assume_role_policy_doc)\n",
    "    logger.info('Creating {} ...'.format(glue_role_name))\n",
    "    glue_iam_role = iam_client.create_role(\n",
    "        RoleName=glue_role_name,\n",
    "        AssumeRolePolicyDocument=assume_role_policy_doc_json,\n",
    "    )\n",
    "    time.sleep(10)\n",
    "    \n",
    "except ClientError as e:\n",
    "    logger.error(e)\n",
    "    glue_iam_role = iam_client.get_role(RoleName=glue_role_name)\n",
    "\n",
    "policy_arns = [\n",
    "    'arn:aws:iam::aws:policy/AWSGlueConsoleFullAccess',\n",
    "    'arn:aws:iam::aws:policy/AmazonS3FullAccess',\n",
    "    'arn:aws:iam::aws:policy/CloudWatchLogsFullAccess',\n",
    "]\n",
    "\n",
    "for policy_arn in policy_arns:\n",
    "    iam_client.attach_role_policy(\n",
    "        RoleName=glue_role_name,\n",
    "        PolicyArn=policy_arn\n",
    "    )\n",
    "    time.sleep(5)\n",
    "    \n",
    "logger.info('completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632c34ee-65dd-4c2e-ac47-11d65295ca64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sts_client = boto_session.client(service_name='sts', region_name=region_name)\n",
    "aws_account_id = sts_client.get_caller_identity()['Account']\n",
    "glue_crawler_name = 'demo-nlq-crawler'\n",
    "\n",
    "try:\n",
    "    logger.info('Attempting to create crawler name: {}'.format(glue_crawler_name))\n",
    "    glue_client.create_crawler(\n",
    "        Name=glue_crawler_name,\n",
    "        Role=glue_role_name,\n",
    "        DatabaseName=glue_db_name,\n",
    "        Targets={\n",
    "            'CatalogTargets': [],\n",
    "            'DeltaTargets': [],\n",
    "            'DynamoDBTargets': [],\n",
    "            'HudiTargets': [],\n",
    "            'IcebergTargets': [],\n",
    "            'JdbcTargets': [],\n",
    "            'MongoDBTargets': [],\n",
    "            'S3Targets': [{\n",
    "                'Exclusions': [],\n",
    "                'Path': 's3://{0}/{1}/'.format(s3_bucket_name, s3_prefix_name)\n",
    "            }],\n",
    "        },\n",
    "        Classifiers=[],\n",
    "        Configuration='{\"Version\": 1.0, \"CreatePartitionIndex\": true}',\n",
    "        LakeFormationConfiguration={\n",
    "            'AccountId': aws_account_id,\n",
    "            'UseLakeFormationCredentials': False\n",
    "        },\n",
    "        RecrawlPolicy={\n",
    "            'RecrawlBehavior': 'CRAWL_EVERYTHING'\n",
    "        },\n",
    "        LineageConfiguration={\n",
    "            'CrawlerLineageSettings': 'ENABLE',\n",
    "        },\n",
    "    )\n",
    "\n",
    "except ClientError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d44561-a8c4-438d-a732-f0819357c4bc",
   "metadata": {},
   "source": [
    "### Start Glue Crawler\n",
    "---\n",
    "\n",
    "This should take no more than 4 minutes to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0310c5f-9de4-4ade-ac93-9b2b4105d158",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "crawler_resp = glue_client.get_crawler(\n",
    "    Name=glue_crawler_name\n",
    ")\n",
    "\n",
    "if crawler_resp['Crawler']['State'] == 'READY':\n",
    "    logger.info('Start crawler...')\n",
    "    resp_ = glue_client.start_crawler(Name=glue_crawler_name)\n",
    "    time.sleep(240)\n",
    "    logger.info('Crawl should be complete....')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb793104-2047-4075-abdd-0a0a7deeaa72",
   "metadata": {},
   "source": [
    "We can check the last crawl status by using below command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0666b3-9542-4c22-a34c-843761d8f8c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger.info('Last crawl status: {}'.format(\n",
    "    glue_client.get_crawler(Name=glue_crawler_name)['Crawler']['LastCrawl']['Status']\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23739e77-8f40-4d41-988e-59112b3f3cb4",
   "metadata": {},
   "source": [
    "## Anthropic Claude on Amazon Bedrock\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Prerequisite:</b> Ensure that you have model access on Amazon Bedrock console page.\n",
    "</div>\n",
    "\n",
    "\n",
    "### Check model ID \n",
    "---\n",
    "We can list the available foundation models by using `list_foundation_models()`, for this demonstration I will pick Sonnet foundation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cb5b0a-79c8-49eb-810e-0a7b5d84731f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bedrock_client = boto_session.client(\n",
    "    service_name='bedrock', \n",
    "    region_name=region_name\n",
    ")\n",
    "\n",
    "[model['modelId'] for model in bedrock_client.list_foundation_models()['modelSummaries'] \\\n",
    "   if ('claude-3' in model['modelId'].lower()) & ('ON_DEMAND' in model['inferenceTypesSupported']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9f41f7-e3f2-4cb7-9b6d-4ca4143d5438",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sonnet_model_id = 'anthropic.claude-3-sonnet-20240229-v1:0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff16405-bc0a-462d-8dcc-5a416f683e86",
   "metadata": {},
   "source": [
    "### Invoke Claude foundation model on Amazon Bedrock using boto3 SDK\n",
    "---\n",
    "\n",
    "In this example, I will use `converse` API to call **Claude Sonnet foundation model** for more details on converse API, please refer to this [documentation](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/bedrock-runtime/client/converse.html). \n",
    "\n",
    "**Converse** API provides a consistent interface that works with all models that support messages. This allows you to write code once and use it with different models. If a model has unique inference parameters, you can also pass those unique parameters to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c21d9f-103f-4464-a4bc-8b2a0eaae19c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def converse_sql_generator(\n",
    "    user_question: str,\n",
    "    model_id: str,\n",
    "    max_tokens: int=3000,\n",
    "    temperature: float=0.,\n",
    "    full_image_filename: str='../schema_img/schema.png',\n",
    "    boto_session: boto3.session.Session=boto_session\n",
    ") -> dict:\n",
    "\n",
    "    with open(full_image_filename, 'rb') as image_file:\n",
    "        image_bytes = image_file.read()\n",
    "    \n",
    "    bedrock_runtime_client = boto_session.client(\n",
    "        service_name='bedrock-runtime',\n",
    "        region_name=boto_session.region_name,\n",
    "    )\n",
    "    \n",
    "    message = {\n",
    "        'role': 'user',\n",
    "        'content': [{\n",
    "            'text': '''\n",
    "            You are a SQL statement generation expert, and are assigned to generate SQL statements executed on Amazon Athena.\n",
    "            Amazon Athena built on open-source Trino and Presto engines, so your SQL should be executed successfully on Presto.\n",
    "\n",
    "            You will be given the image of ERD (Entity Relationship Diagram), which represent the relationship of tables, primary, and join key. \n",
    "\n",
    "            Read it and ensure you understand the database structures.\n",
    "            It is IMPORTANT to respect the type of columns: if a column is string, the value should be enclosed in quotes.\n",
    "            While concatenating a non string column, make sure to cast the column to string.\n",
    "            For date columns comparing to string, please cast the string input.\n",
    "\n",
    "            First, you will need to list what tables are in the diagram and what are the join keys for each table!\n",
    "            Secondly, You will be presented with the question within <question> tag.\n",
    "            Lastly, generate the SQL to get the answer for the question using relationship from the given image.\n",
    "\n",
    "            <question>\n",
    "            {0}\n",
    "            </question>\n",
    "\n",
    "            If you cannot generate the SQL from the attached diagram, respond with \"Sorry, there're not information to generate the SQL query\".\n",
    "            Once you generate the SQL query, reexamine your SQL again! \n",
    "\n",
    "            1. Make sure the columns exist in each table as in the given image!\n",
    "            2. Make sure the join keys in each table are correct according to the given image!\n",
    "\n",
    "            Your final answer will be in XML format.\n",
    "            <result>\n",
    "            <sql>SQL query</sql>\n",
    "            <explanation>Explain clearly your approach, what the query does, and its syntax</explanation>\n",
    "            </result>\n",
    "            \n",
    "            '''.format(user_question),\n",
    "        }, {\n",
    "            'image': {\n",
    "                'format': 'png',\n",
    "                'source': {\n",
    "                    'bytes': image_bytes\n",
    "                }\n",
    "            },\n",
    "        }],\n",
    "    }\n",
    "    \n",
    "    inference_config = {\n",
    "        'maxTokens': max_tokens,\n",
    "        'temperature': temperature\n",
    "    }\n",
    "    \n",
    "    converse_response = bedrock_runtime_client.converse(\n",
    "        modelId=model_id,\n",
    "        messages=[message],\n",
    "        inferenceConfig=inference_config,\n",
    "    )\n",
    "    return converse_response\n",
    "\n",
    "\n",
    "def get_text_output(converse_resp: dict) -> str:\n",
    "    return converse_resp['output']['message']['content'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94aff75-2cba-4f20-911a-a8b3dcb540cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_question = 'How many projects are we having?'\n",
    "resp = converse_sql_generator(\n",
    "    model_id=sonnet_model_id,\n",
    "    user_question=test_question,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444ee318-a2fd-4d6a-84d3-3fdc969c370b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_answer = get_text_output(resp)\n",
    "print(test_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc8a4c0-52ce-470e-872b-bee1de33640c",
   "metadata": {},
   "source": [
    "Moreover, you can access tokens usage and latency metrics from the `converse` API output as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ce579d-dc03-4276-b493-f55b88dbc3e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(resp['metrics'])\n",
    "print(resp['usage'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de03f618-967c-44ee-ae60-9c8711075fc9",
   "metadata": {},
   "source": [
    "Let's quickly test our functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c57feb2-f45a-495c-b35d-a9f8be8f83dc",
   "metadata": {},
   "source": [
    "## Query the data lake using Amazon Athena\n",
    "---\n",
    "\n",
    "Because we have crawled the data using **Glue data crawler**, we can use **Amazon Athena** service to query the data.\n",
    "There are several steps to call and get the query result from Amazon Athena.\n",
    "\n",
    "1. Start query execution\n",
    "2. Get the query state\n",
    "3. Once it is *SUCCEED*, get the query result\n",
    "\n",
    "Let's create the function to encapsulate these steps!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ce34dc-f0d2-4b84-8e0e-e1e5b8fefb59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_sql_script(\n",
    "    string_resp_from_llm: str\n",
    ") -> str:\n",
    "    '''Function to get SQL query from <sql> tag\n",
    "    '''\n",
    "    sql_output = string_resp_from_llm.split('<sql>')[1].split('</sql>')[0]\n",
    "    return sql_output\n",
    "\n",
    "\n",
    "def call_athena(\n",
    "    sql_script: str,\n",
    "    glue_db_name: str=glue_db_name,\n",
    "    boto_session: boto3.session.Session=boto_session\n",
    ") -> Optional[List[dict]]:\n",
    "    '''\n",
    "    Function to call Amazon Athena and use the provided SQL query, and wait to get the query result\n",
    "    :param sql_script: the SQL script to run against Amazon Athena\n",
    "    :param boto_session: boto3 session (default: boto_session)\n",
    "    \n",
    "    :return: the list of SQL results returning from Amazon Athena\n",
    "    '''    \n",
    "    def _start_query_execution_(\n",
    "        sql_script: str=sql_script,\n",
    "        boto_session: boto3.session.Session=boto_session\n",
    "    ) -> Optional[str]:\n",
    "        ''' Function to call Amazon Athena and use the provided SQL query\n",
    "        :param sql_script: the SQL script to run against Amazon Athena\n",
    "        :param boto_session: boto3 session (default: boto_session)\n",
    "        \n",
    "        :return: the execution ID used for further tracking and result retrieval\n",
    "        '''\n",
    "        execution_id = None\n",
    "        athena_client = boto_session.client(service_name='athena', region_name=boto_session.region_name)\n",
    "        \n",
    "        try:\n",
    "            logger.info('Start query execution on Amazon Athena...')\n",
    "            query_response = athena_client.start_query_execution(\n",
    "                QueryString=sql_script,\n",
    "                ResultConfiguration={\n",
    "                    'OutputLocation': 's3://{}/athena-query-results/'.format(s3_bucket_name),\n",
    "                    'EncryptionConfiguration': {\n",
    "                        'EncryptionOption': 'SSE_S3',\n",
    "                    },\n",
    "                },\n",
    "                QueryExecutionContext={\n",
    "                    'Database': glue_db_name,\n",
    "                },\n",
    "            )\n",
    "            execution_id = query_response[\"QueryExecutionId\"]\n",
    "            logger.info('SQL script is executing ...')\n",
    "            logger.info('Query execution ID: {} ...'.format(execution_id))\n",
    "        \n",
    "        except ClientError as e:\n",
    "            logger.error('The provided SQL query has syntax error!!')\n",
    "            logger.error(e)\n",
    "            \n",
    "        return execution_id\n",
    "    \n",
    "    \n",
    "    def _get_query_state_(\n",
    "        execution_id: str,\n",
    "        boto_session: boto3.session.Session=boto_session\n",
    "    ) -> Optional[Tuple[str, dict]]:\n",
    "        ''' \n",
    "        Function to get the query state from Amazon Athena\n",
    "        Remark: possible query state is 'QUEUED', 'RUNNING', 'SUCCEEDED', 'FAILED', or 'CANCELLED'\n",
    "        :param execution_id: the execution ID used for further tracking and result retrieval\n",
    "        :param boto_session: boto3 session (default: boto_session)\n",
    "\n",
    "        :return: Tuple of the query state and response dictionary containing details (i.e., data scan, run time)\n",
    "        '''\n",
    "        athena_client = boto_session.client(service_name='athena', region_name=boto_session.region_name)\n",
    "        try:\n",
    "            get_query_state_resp = athena_client.get_query_execution(QueryExecutionId=execution_id)\n",
    "            _query_state = get_query_state_resp['QueryExecution']['Status']['State']\n",
    "            logger.info('The current query state is {} ...'.format(_query_state))\n",
    "            return _query_state, get_query_state_resp['QueryExecution']\n",
    "\n",
    "        except ClientError as e:\n",
    "            logger.error('Something went wrong when trying to get query state')\n",
    "            logger.error(e)\n",
    "            raise(e)\n",
    "            \n",
    "            \n",
    "    def _get_query_result_(\n",
    "        execution_id: str,\n",
    "        boto_session: boto3.session.Session=boto_session\n",
    "    ) -> Optional[List[dict]]:\n",
    "        athena_client = boto_session.client(service_name='athena', region_name=boto_session.region_name)\n",
    "        try:\n",
    "            logger.info('Retrieving the SQL result ...')\n",
    "            query_result_resp = athena_client.get_query_results(QueryExecutionId=execution_id)\n",
    "            logger.info('Finish fetching result =) .... ')\n",
    "            return query_result_resp['ResultSet']['Rows']\n",
    "            \n",
    "        except ClientError as e:\n",
    "            logger.error('Cannot get SQL result...')\n",
    "            logger.error(e)\n",
    "            raise(e)\n",
    "    \n",
    "    execution_id = _start_query_execution_()\n",
    "    _query_state, _query_resp_dict = _get_query_state_(execution_id=execution_id)\n",
    "    while (_query_state != 'FAILED') and (_query_state != 'SUCCEEDED'):\n",
    "        time.sleep(5)\n",
    "        _query_state, _query_resp_dict = _get_query_state_(execution_id=execution_id)\n",
    "        \n",
    "    query_result = _get_query_result_(execution_id=execution_id)\n",
    "        \n",
    "    return query_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb092959-8ab8-4044-a3f9-6157f242d106",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_query_result = call_athena(get_sql_script(test_answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c73e58-e7ce-4ba8-8c87-ed09faa4c487",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_query_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c35004e-a1ac-4ef3-a440-f0addf10b5b4",
   "metadata": {},
   "source": [
    "As we can see the result are returned in more technical manner, we will use this output to feed onto another foundation model to summarize and return results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b9a1fb-4514-448f-a256-9b8ecc48bee7",
   "metadata": {},
   "source": [
    "## Summarize the output to human-friendly text\n",
    "---\n",
    "\n",
    "Ultimately, you would live your generative AI application to respond back in more natural manner instead of technical format like list, or dictionary format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a3dc35-31bc-409a-8a25-c4d6c28a414a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def converse_answer_generator(\n",
    "    user_question: str,\n",
    "    sql_response: List[dict],\n",
    "    model_id: str,\n",
    "    max_tokens: int=3000,\n",
    "    temperature: float=0.,\n",
    "    boto_session: boto3.session.Session=boto_session\n",
    ") -> dict:\n",
    "    logger.info('Generating final response from the provided question and SQL result ...')\n",
    "    bedrock_runtime_client = boto_session.client(\n",
    "        service_name='bedrock-runtime',\n",
    "        region_name=boto_session.region_name,\n",
    "    )\n",
    "    ans_generator_template = '''\n",
    "    You are to answer the question in <question> tag to the best of your ability based on the given context in <context> tag.\n",
    "    \n",
    "    The context are kept in Dictionary format within List data type.\n",
    "    The first element of list is the column, and the second element of is the actual data.\n",
    "    If there is only one element in the list, this means that there's no result returned.\n",
    "    As such, the context means there's no or 0 for their question. \n",
    "    \n",
    "    Your response should be PRECISE!!! TRY NOT TO REPEAT THE QUESTION WHEN RESPONSE! \n",
    "    AND GIVE ONLY THE ANSWER, No need to reiterate the context!\n",
    "    \n",
    "    Do not include information that is not relevant to the question.\n",
    "    Only provide information based on the context provided, and do not make assumptions!\n",
    "\n",
    "    <question>\n",
    "    {question}\n",
    "    </question>\n",
    "\n",
    "    <context>\n",
    "    {context}\n",
    "    </context\n",
    "    '''.format(question=user_question, context=sql_response)\n",
    "    \n",
    "    message = {\n",
    "        'role': 'user',\n",
    "        'content': [{\n",
    "            'text': ans_generator_template,\n",
    "        },],\n",
    "    }\n",
    "    \n",
    "    inference_config = {\n",
    "        'maxTokens': max_tokens,\n",
    "        'temperature': temperature\n",
    "    }\n",
    "    \n",
    "    converse_response = bedrock_runtime_client.converse(\n",
    "        modelId=model_id,\n",
    "        messages=[message],\n",
    "        inferenceConfig=inference_config,\n",
    "    )\n",
    "    return converse_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a1b0d7-82ff-4a61-8e4f-97ec1740c2e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resp2 = converse_answer_generator(\n",
    "    user_question=test_question,\n",
    "    sql_response=test_query_result,\n",
    "    model_id=haiku_model_id,\n",
    ")\n",
    "print(get_text_output(resp2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18a0c0e-e6b3-487d-9ad2-3c13a838fe14",
   "metadata": {},
   "source": [
    "## Put it all together\n",
    "---\n",
    "Let's test it several questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32da806-860f-4a84-bca1-a64a64cb3de8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question_01 = 'How many employees are there?'\n",
    "question_02 = 'Who are working on each of the projects?'\n",
    "question_03 = 'What is the least project we are spending time on? And who are in the projects and how much time spent?'\n",
    "question_04 = 'List top 3 employees who have spending the time on the project the most.'\n",
    "question_05 = 'Are there any employees working on multiple projects? If yes, what is the project and the time spent on each project?'\n",
    "\n",
    "question_list = [question_01, question_02, question_03, question_04, question_05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56625bf1-7654-43e4-a252-d63060f468fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "for question in question_list:\n",
    "    _sql_resp = converse_sql_generator(\n",
    "        model_id=sonnet_model_id,\n",
    "        user_question=question,\n",
    "    )\n",
    "    _generate_sql = get_sql_script(get_text_output(_sql_resp))\n",
    "    _athena_query_result = call_athena(_generate_sql)\n",
    "    _answer_resp = converse_answer_generator(\n",
    "        user_question=question,\n",
    "        sql_response=_athena_query_result,\n",
    "        model_id=sonnet_model_id,\n",
    "    )\n",
    "    _answer = get_text_output(_answer_resp)\n",
    "    display(Markdown('**Question:** <span style=\"color: #ff0000\">{}</span>'.format(question)))\n",
    "    display(Markdown('**Answer:** <span style=\"color: #0000FF\">{}</span>'.format(_answer)))\n",
    "    display(Markdown('**SQL Generated:** <span style=\"color: #A020F0\">{}</span>'.format(_generate_sql)))\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83d2068-1ac8-4939-8291-3dcba0586c31",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "---\n",
    "\n",
    "Once you are done with experiment, please ensure you have deleted all resources in this demonstration to prevent any incur cost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b98be9-fd8b-41c0-8420-3423582cc180",
   "metadata": {},
   "source": [
    "### Clean up data uploaded to Amazon S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cd79bf-10d1-465f-a0f2-2448c8b13cce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for file in file_list:\n",
    "    file_ext = file.split('.')[-1]\n",
    "    file_nm = file.split('.')[0]\n",
    "    logger.info('Deleting {0}/{1}/{2} ...'.format(s3_prefix_name, file_nm, file))\n",
    "    try:\n",
    "        _ = s3_client.delete_objects(\n",
    "            Bucket=s3_bucket_name,\n",
    "            Delete={\n",
    "                'Objects': [{\n",
    "                    'Key': '{0}/{1}/{2}'.format(s3_prefix_name, file_nm, file),\n",
    "                },],\n",
    "                'Quiet': True\n",
    "            },\n",
    "        )\n",
    "    except Exception as e:\n",
    "        logger.error('Something is wrong! {}'.format(e))\n",
    "        raise(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16ea647-8455-42c5-b1b3-15d0559db0d0",
   "metadata": {},
   "source": [
    "### Detach IAM policies and delete IAM role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf461d8-7fdb-423e-8683-26f7076ad8b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for policy_arn in policy_arns:\n",
    "    iam_client.detach_role_policy(\n",
    "        RoleName=glue_role_name,\n",
    "        PolicyArn=policy_arn\n",
    "    )\n",
    "    time.sleep(5)\n",
    "\n",
    "_ = iam_client.delete_role(\n",
    "    RoleName=glue_role_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07853f81-32c4-4cb6-a507-9dd675a194b0",
   "metadata": {},
   "source": [
    "### Delete Glue database and Glue Crawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58de0c4b-db54-4738-aa36-68ddad09c194",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_ = glue_client.delete_database(\n",
    "    Name=glue_db_name,\n",
    ")\n",
    "_ = glue_client.delete_crawler(\n",
    "    Name=glue_crawler_name,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
